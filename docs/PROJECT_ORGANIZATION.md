# Project Organization Guide

## ğŸ“ **Directory Structure**

```
LongContextRAG/
â”œâ”€â”€ ğŸ“ core/                    # Core configuration and utilities
â”‚   â”œâ”€â”€ config.py              # Main configuration
â”‚   â”œâ”€â”€ prompts.py             # Prompt templates
â”‚   â””â”€â”€ long_context_config.py # Long context settings
â”‚
â”œâ”€â”€ ğŸ“ data/                    # Data storage
â”‚   â”œâ”€â”€ bookcorpus/            # BookCorpus dataset
â”‚   â”œâ”€â”€ bookcorpus_processed/  # Processed BookCorpus
â”‚   â””â”€â”€ pg19_raw/              # PG19 dataset
â”‚
â”œâ”€â”€ ğŸ“ docs/                    # Documentation
â”‚   â”œâ”€â”€ SETUP_GUIDE.md         # Setup instructions
â”‚   â”œâ”€â”€ NARRATIVEQA_EVALUATION_GUIDE.md # Evaluation guide
â”‚   â”œâ”€â”€ BASE_LLM_NARRATIVEQA_SYSTEM_DESIGN.md # Base LLM design
â”‚   â””â”€â”€ RAG_NARRATIVEQA_SYSTEM_DESIGN.md # RAG system design
â”‚
â”œâ”€â”€ ğŸ“ evaluation/              # Evaluation frameworks
â”‚   â”œâ”€â”€ narrativeqa_evaluator.py # Main NarrativeQA evaluator
â”‚   â”œâ”€â”€ qa_metrics.py          # QA-specific metrics
â”‚   â”œâ”€â”€ bleu_evaluator.py      # BLEU evaluation
â”‚   â””â”€â”€ rag_evaluation.py      # RAG evaluation
â”‚
â”œâ”€â”€ ğŸ“ examples/                # Example implementations
â”‚   â”œâ”€â”€ narrativeqa_base_llm.py # Base LLM for NarrativeQA
â”‚   â”œâ”€â”€ narrativeqa_rag_baseline.py # RAG baseline
â”‚   â”œâ”€â”€ standard_rag_baseline.py # Standard RAG
â”‚   â””â”€â”€ compare_responses.py   # Response comparison
â”‚
â”œâ”€â”€ ğŸ“ hybrid/                   # Hybrid RAG implementations
â”‚   â”œâ”€â”€ narrativeqa_hybrid_rag.py # NarrativeQA Hybrid RAG
â”‚   â”œâ”€â”€ working_hybrid_rag.py   # Working Hybrid RAG
â”‚   â”œâ”€â”€ hybrid_attention_rag.py # Hybrid attention RAG
â”‚   â””â”€â”€ hybrid_rag_integration.py # Integration utilities
â”‚
â”œâ”€â”€ ğŸ“ scripts/                 # Organized scripts
â”‚   â”œâ”€â”€ ğŸ“ analysis/            # Analysis scripts
â”‚   â”‚   â”œâ”€â”€ analyze_qa_metrics.py # QA metrics analysis
â”‚   â”‚   â”œâ”€â”€ analyze_bleu_results.py # BLEU analysis
â”‚   â”‚   â”œâ”€â”€ analyze_narrativeqa_comparison.py # Comparison analysis
â”‚   â”‚   â””â”€â”€ summarize_base_llm_results.py # Results summarization
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ comparison/          # Comparison scripts
â”‚   â”‚   â””â”€â”€ compare_systems_narrativeqa.py # System comparison
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ setup/               # Setup scripts
â”‚       â”œâ”€â”€ setup_full_vectordb.py # Vector DB setup
â”‚       â”œâ”€â”€ setup_narrativeqa.py # NarrativeQA setup
â”‚       â””â”€â”€ monitor_build.py    # Build monitoring
â”‚
â”œâ”€â”€ ğŸ“ testing/                 # Testing utilities
â”‚   â”œâ”€â”€ bookcorpus_integration.py # BookCorpus testing
â”‚   â””â”€â”€ start_bookcorpus_testing.py # Testing launcher
â”‚
â”œâ”€â”€ ğŸ“ training/                # Training scripts
â”‚   â”œâ”€â”€ neural_retriever.py    # Neural retriever training
â”‚   â””â”€â”€ train_hybrid_rag.py    # Hybrid RAG training
â”‚
â”œâ”€â”€ ğŸ“ utils/                   # Utility functions
â”‚   â”œâ”€â”€ setup_env.py           # Environment setup
â”‚   â”œâ”€â”€ test_setup.py          # Setup testing
â”‚   â””â”€â”€ token_usage_analysis.py # Token usage analysis
â”‚
â”œâ”€â”€ ğŸ“ VectorDB/                # Vector database utilities
â”‚   â”œâ”€â”€ build_db.py            # Database builder
â”‚   â”œâ”€â”€ build_full_bookcorpus_db.py # Full BookCorpus builder
â”‚   â””â”€â”€ vectordb_manager.py    # Database manager
â”‚
â”œâ”€â”€ ğŸ“ results/                 # Evaluation results
â”‚   â””â”€â”€ bookcorpus/            # BookCorpus results
â”‚
â”œâ”€â”€ run.py                     # Main script runner
â”œâ”€â”€ main.py                    # Main entry point
â”œâ”€â”€ requirements.txt           # Core dependencies
â”œâ”€â”€ requirements_narrativeqa.txt # NarrativeQA dependencies
â””â”€â”€ README.md                  # Project overview
```

## ğŸš€ **Script Organization**

### **Main Script Runner**
The `run.py` script provides easy access to all organized scripts:

```bash
# Setup scripts
python run.py setup-vectordb --build-medium
python run.py setup-narrativeqa
python run.py monitor-build

# Comparison scripts
python run.py compare-systems --systems base_llm,narrativeqa_hybrid_rag --num-questions 5

# Analysis scripts
python run.py analyze-qa
python run.py analyze-bleu
python run.py analyze-comparison
python run.py summarize-results
```

### **Direct Script Access**
You can also run scripts directly:

```bash
# Analysis scripts
python scripts/analysis/analyze_qa_metrics.py
python scripts/analysis/analyze_bleu_results.py

# Comparison scripts
python scripts/comparison/compare_systems_narrativeqa.py --systems base_llm --num-questions 5

# Setup scripts
python scripts/setup/setup_full_vectordb.py --build-medium
python scripts/setup/monitor_build.py
```

## ğŸ“‹ **Script Categories**

### **ğŸ”§ Setup Scripts (`scripts/setup/`)**
- **`setup_full_vectordb.py`**: Build BookCorpus vector database
- **`setup_narrativeqa.py`**: Setup NarrativeQA evaluation
- **`monitor_build.py`**: Monitor database build progress

### **âš–ï¸ Comparison Scripts (`scripts/comparison/`)**
- **`compare_systems_narrativeqa.py`**: Compare RAG systems on NarrativeQA

### **ğŸ“Š Analysis Scripts (`scripts/analysis/`)**
- **`analyze_qa_metrics.py`**: Analyze QA evaluation results
- **`analyze_bleu_results.py`**: Analyze BLEU evaluation results
- **`analyze_narrativeqa_comparison.py`**: Analyze system comparison results
- **`summarize_base_llm_results.py`**: Summarize base LLM results

## ğŸ¯ **Usage Examples**

### **Quick Evaluation**
```bash
# Run quick comparison
python run.py compare-systems --systems base_llm,narrativeqa_hybrid_rag --num-questions 2

# Analyze results
python run.py analyze-qa
```

### **Comprehensive Evaluation**
```bash
# Run full comparison
python run.py compare-systems --systems base_llm,narrativeqa_hybrid_rag,narrativeqa_rag --num-questions 10

# Analyze all metrics
python run.py analyze-qa
python run.py analyze-bleu
```

### **Setup and Monitoring**
```bash
# Setup vector database
python run.py setup-vectordb --build-medium

# Monitor build progress
python run.py monitor-build

# Setup NarrativeQA
python run.py setup-narrativeqa
```

## ğŸ“š **Documentation Organization**

### **Setup and Configuration**
- **`SETUP_GUIDE.md`**: Initial project setup
- **`NARRATIVEQA_EVALUATION_GUIDE.md`**: Evaluation instructions

### **System Design**
- **`BASE_LLM_NARRATIVEQA_SYSTEM_DESIGN.md`**: Base LLM architecture
- **`RAG_NARRATIVEQA_SYSTEM_DESIGN.md`**: RAG system design

### **Project Organization**
- **`PROJECT_ORGANIZATION.md`**: This file - project structure guide

## ğŸ”„ **Migration from Old Structure**

### **Before (Scattered Scripts)**
```bash
# Scripts were in main directory
python compare_systems_narrativeqa.py --systems base_llm --num-questions 5
python analyze_qa_metrics.py
python setup_full_vectordb.py --build-medium
```

### **After (Organized Structure)**
```bash
# Using main runner (recommended)
python run.py compare-systems --systems base_llm --num-questions 5
python run.py analyze-qa
python run.py setup-vectordb --build-medium

# Or direct access
python scripts/comparison/compare_systems_narrativeqa.py --systems base_llm --num-questions 5
python scripts/analysis/analyze_qa_metrics.py
python scripts/setup/setup_full_vectordb.py --build-medium
```

## âœ… **Benefits of Organization**

### **1. Clear Separation of Concerns**
- **Setup scripts**: Database and environment setup
- **Comparison scripts**: System evaluation
- **Analysis scripts**: Results analysis

### **2. Easy Discovery**
- **`run.py`**: Single entry point for all scripts
- **Organized directories**: Clear script categories
- **Documentation**: Comprehensive usage guides

### **3. Maintainability**
- **Modular structure**: Easy to add new scripts
- **Clear dependencies**: Scripts in appropriate folders
- **Consistent patterns**: Similar scripts grouped together

### **4. User Experience**
- **Simple commands**: `python run.py <command>`
- **Help system**: Built-in help and examples
- **Flexible access**: Direct script access when needed

This organization makes the project much more maintainable and user-friendly! ğŸ¯
